{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4da89eb",
   "metadata": {},
   "source": [
    "ğŸ§© CÃ©lula 1 â€“ ImportaÃ§Ã£o de biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6bf49359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from shutil import move\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ab227f",
   "metadata": {},
   "source": [
    "âœ… Fazer o backup com a data atual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a4874a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Arquivo consolidado anterior movido para backup: C:\\Aplicativos\\Meus_Arquivos_Willian\\Ambiente_Desenvolvimento\\Arquivos_in\\Vendas\\Backup\\Backup_2025-08-11_Arquivo_Consolidado.xlsx\n",
      "ğŸ§¹ Backup antigo removido: Backup_2025-08-04_Arquivo_Consolidado.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ Caminhos e nomes de arquivos\n",
    "pasta_origem = \"C:\\Aplicativos\\Meus_Arquivos_Willian\\Ambiente_Desenvolvimento\\Arquivos_in\\Vendas\"\n",
    "nome_arquivo = \"Arquivo_Consolidado.xlsx\"\n",
    "\n",
    "# ğŸ“… Data atual formatada\n",
    "data_hoje = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# ğŸ“ Pasta de backup\n",
    "pasta_backup = os.path.join(pasta_origem, \"Backup\")\n",
    "os.makedirs(pasta_backup, exist_ok=True)\n",
    "\n",
    "# ğŸ§­ Verifica e move o arquivo consolidado anterior\n",
    "if os.path.exists(caminho_consolidado):\n",
    "    nome_backup = f\"Backup_{data_hoje}_{nome_arquivo}\"\n",
    "    caminho_backup = os.path.join(pasta_backup, nome_backup)\n",
    "    move(caminho_consolidado, caminho_backup)\n",
    "    print(f\"ğŸ“¦ Arquivo consolidado anterior movido para backup: {caminho_backup}\")\n",
    "\n",
    "# ğŸ•’ Limpeza de backups antigos (mantÃ©m Ãºltimos 7 dias)\n",
    "limite_dias = 7\n",
    "data_limite = datetime.now() - timedelta(days=limite_dias)\n",
    "\n",
    "for arquivo in os.listdir(pasta_backup):\n",
    "    caminho_arquivo = os.path.join(pasta_backup, arquivo)\n",
    "\n",
    "    if arquivo.startswith(\"Backup_\") and arquivo.endswith(\".xlsx\"):\n",
    "        try:\n",
    "            data_str = arquivo.split(\"_\")[1]\n",
    "            data_arquivo = datetime.strptime(data_str, \"%Y-%m-%d\")\n",
    "\n",
    "            if data_arquivo < data_limite:\n",
    "                os.remove(caminho_arquivo)\n",
    "                print(f\"ğŸ§¹ Backup antigo removido: {arquivo}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ NÃ£o foi possÃ­vel processar o arquivo '{arquivo}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fc6f7",
   "metadata": {},
   "source": [
    "ğŸ“‚ 1. DefiniÃ§Ã£o do diretÃ³rio e leitura dos arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d5670c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ Log anterior removido.\n",
      "ğŸ“‚ Arquivos encontrados para consolidaÃ§Ã£o:\n",
      "   - Vendas2021.xlsx\n",
      "   - Vendas2026.xlsx\n",
      "âœ… Todos os arquivos estÃ£o vÃ¡lidos. Pronto para consolidar!\n",
      "ğŸ“ Log de duplicatas salvo em: C:\\Aplicativos\\Meus_Arquivos_Willian\\Ambiente_Desenvolvimento\\Arquivos_in\\Vendas\\Log_Duplicatas.txt\n",
      "âœ… Novo arquivo consolidado criado em: C:\\Aplicativos\\Meus_Arquivos_Willian\\Ambiente_Desenvolvimento\\Arquivos_in\\Vendas\\Arquivo_Consolidado.xlsx\n",
      "ğŸ“Š Registros antes da remoÃ§Ã£o de duplicatas: 33\n",
      "ğŸ“‰ Registros apÃ³s remoÃ§Ã£o de duplicatas: 31\n",
      "ğŸ§¹ Total de duplicatas removidas: 2\n",
      "\n",
      "ğŸ“„ ConteÃºdo do Log_Duplicatas.txt:\n",
      "ğŸ” REGISTROS DUPLICADOS ENCONTRADOS:\n",
      "\n",
      "      Data  Id Venda  IdCategoria  Categoria  IdPais   Pais  idProduto    Produto  Custo fabricacao  Unidades Vendidas  Preco venda  Vendas total  Descontos  Arquivo_Origem\n",
      "2021-04-12       760            4 AcessÃ³rios     638 MÃ©xico          2 Braceletes               250                939           15         14085      908.4 Vendas2021.xlsx\n",
      "2021-04-12       760            4 AcessÃ³rios     638 MÃ©xico          2 Braceletes               250                939           15         14085      908.4 Vendas2021.xlsx\n",
      "2025-08-11      1109            1       Moda     638 MÃ©xico          5   Camiseta                10               1199           20         23980     2959.2 Vendas2026.xlsx\n",
      "2025-08-11      1109            1       Moda     638 MÃ©xico          5   Camiseta                10               1199           20         23980     2959.2 Vendas2026.xlsx\n",
      "\n",
      "ğŸ“Š EstatÃ­sticas do DataFrame consolidado:\n",
      "ğŸ“… Data mÃ­nima: 2021-04-02 00:00:00\n",
      "ğŸ“… Data mÃ¡xima: 2025-08-12 00:00:00\n",
      "\n",
      "ğŸ“… VisÃ£o por Data e Qtd:         Data  Quantidade\n",
      "0 2021-04-02           4\n",
      "1 2021-04-06           2\n",
      "2 2021-04-09           3\n",
      "3 2021-04-10           4\n",
      "4 2021-04-11           1\n",
      "5 2021-04-12           7\n",
      "6 2025-08-11           9\n",
      "7 2025-08-12           1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "caminho_consolidado = os.path.join(pasta_origem, nome_arquivo)\n",
    "caminho_log = os.path.join(pasta_origem, \"Log_Duplicatas.txt\")\n",
    "\n",
    "# ğŸ—‚ï¸ Apagar o arquivo de log\n",
    "if os.path.exists(caminho_log):\n",
    "    os.remove(caminho_log)\n",
    "    print(\"ğŸ—‘ï¸ Log anterior removido.\")\n",
    "    \n",
    "# ğŸ“¦ Lista para armazenar os DataFrames\n",
    "dados = []\n",
    "\n",
    "# ğŸ§© FunÃ§Ã£o para verificar arquivos\n",
    "def verificar_arquivos(pasta_origem, nome_arquivo):\n",
    "    arquivos_encontrados = [\n",
    "        arquivo for arquivo in os.listdir(pasta_origem)\n",
    "        if arquivo.endswith('.xlsx') and arquivo != nome_arquivo\n",
    "    ]\n",
    "\n",
    "    if not arquivos_encontrados:\n",
    "        print(\"âš ï¸ Nenhum arquivo de vendas encontrado para consolidar.\")\n",
    "        print(\"âœ… O arquivo consolidado existente foi mantido.\")\n",
    "        return None\n",
    "\n",
    "    print(\"ğŸ“‚ Arquivos encontrados para consolidaÃ§Ã£o:\")\n",
    "    for arquivo in arquivos_encontrados:\n",
    "        print(\"   -\", arquivo)\n",
    "\n",
    "    return arquivos_encontrados\n",
    "\n",
    "# ğŸ§© FunÃ§Ã£o para validar layout\n",
    "def validar_layout(arquivos_encontrados, layout_esperado, pasta_origem):\n",
    "    arquivos_invalidos = []\n",
    "\n",
    "    for arquivo in arquivos_encontrados:\n",
    "        caminho_arquivo = os.path.join(pasta_origem, arquivo)\n",
    "        df = pd.read_excel(caminho_arquivo)\n",
    "        colunas_encontradas = list(df.columns)\n",
    "\n",
    "        if sorted(colunas_encontradas) != sorted(layout_esperado):\n",
    "            arquivos_invalidos.append((arquivo, colunas_encontradas))\n",
    "\n",
    "    if arquivos_invalidos:\n",
    "        for arquivo, colunas in arquivos_invalidos:\n",
    "            print(f\"\\nâŒ ERRO: O arquivo ->'{arquivo}'<- estÃ¡ fora do layout esperado.\")\n",
    "            print(\"ğŸ“Œ Colunas encontradas:\")\n",
    "            print(\"   \", colunas)\n",
    "            print(\"âœ… Colunas esperadas:\")\n",
    "            print(\"   \", layout_esperado)\n",
    "        print(\"\\nğŸš« ConsolidaÃ§Ã£o interrompida. Corrija os arquivos e execute novamente.\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# ğŸ“‹ Define o layout esperado\n",
    "layout_esperado = [\n",
    "    'Data', 'Id Venda', 'IdCategoria', 'Categoria', 'IdPais', 'Pais',\n",
    "    'idProduto', 'Produto', 'Custo fabricacao', 'Unidades Vendidas',\n",
    "    'Preco venda', 'Vendas total', 'Descontos'\n",
    "]\n",
    "\n",
    "# ğŸ” Verifica arquivos\n",
    "arquivos_encontrados = verificar_arquivos(pasta_origem, nome_arquivo)\n",
    "\n",
    "if arquivos_encontrados is None:\n",
    "    print(\"â¹ï¸ ExecuÃ§Ã£o encerrada.\")\n",
    "else:\n",
    "    if not validar_layout(arquivos_encontrados, layout_esperado, pasta_origem):\n",
    "        print(\"â¹ï¸ ExecuÃ§Ã£o encerrada.\")\n",
    "    else:\n",
    "        print(\"âœ… Todos os arquivos estÃ£o vÃ¡lidos. Pronto para consolidar!\")\n",
    "\n",
    "        # âœ… Leitura e concatenaÃ§Ã£o\n",
    "        for arquivo in arquivos_encontrados:\n",
    "            caminho_arquivo = os.path.join(pasta_origem, arquivo)\n",
    "            df = pd.read_excel(caminho_arquivo)\n",
    "            df['Arquivo_Origem'] = arquivo\n",
    "            dados.append(df)\n",
    "\n",
    "        # ğŸ”— Concatena todos os DataFrames vÃ¡lidos\n",
    "        Dados_consolidado = pd.concat(dados, ignore_index=True)\n",
    "\n",
    "        # ğŸ“Š Contagem antes da remoÃ§Ã£o de duplicatas\n",
    "        total_antes = Dados_consolidado.shape[0]\n",
    "\n",
    "        # ğŸ” Identifica duplicatas (sem considerar a coluna 'Arquivo_Origem')\n",
    "        colunas_para_verificar = [col for col in Dados_consolidado.columns if col != 'Arquivo_Origem']\n",
    "        duplicatas = Dados_consolidado[Dados_consolidado.duplicated(subset=colunas_para_verificar, keep=False)]\n",
    "\n",
    "        # ğŸ“ Salva duplicatas no log\n",
    "        if not duplicatas.empty:\n",
    "            with open(caminho_log, \"w\", encoding=\"utf-8\") as log:\n",
    "                log.write(\"ğŸ” REGISTROS DUPLICADOS ENCONTRADOS:\\n\\n\")\n",
    "                log.write(duplicatas.to_string(index=False))\n",
    "            print(f\"ğŸ“ Log de duplicatas salvo em: {caminho_log}\")\n",
    "        else:\n",
    "            print(\"âœ… Nenhuma duplicata encontrada. Nenhum log gerado.\")\n",
    "\n",
    "        # ğŸ§¹ Remove duplicidades mantendo o primeiro registro\n",
    "        Dados_consolidado.drop_duplicates(subset=colunas_para_verificar, inplace=True)\n",
    "\n",
    "        # ğŸ“‰ Contagem depois da remoÃ§Ã£o\n",
    "        total_depois = Dados_consolidado.shape[0]\n",
    "        duplicatas_removidas = total_antes - total_depois\n",
    "\n",
    "        # ğŸ—‘ï¸ Remove o arquivo consolidado anterior, se existir\n",
    "        if os.path.exists(caminho_consolidado):\n",
    "            os.remove(caminho_consolidado)\n",
    "            print(\"ğŸ—‘ï¸ Arquivo consolidado anterior removido.\")\n",
    "\n",
    "        # ğŸ’¾ Salva o novo consolidado\n",
    "        Dados_consolidado.to_excel(caminho_consolidado, index=False)\n",
    "\n",
    "        # ğŸ“£ Mensagens finais\n",
    "        print(\"âœ… Novo arquivo consolidado criado em:\", caminho_consolidado)\n",
    "        print(f\"ğŸ“Š Registros antes da remoÃ§Ã£o de duplicatas: {total_antes}\")\n",
    "        print(f\"ğŸ“‰ Registros apÃ³s remoÃ§Ã£o de duplicatas: {total_depois}\")\n",
    "        print(f\"ğŸ§¹ Total de duplicatas removidas: {duplicatas_removidas}\")\n",
    "\n",
    "        # ğŸ“„ Exibe o conteÃºdo do log de duplicatas no console\n",
    "        if os.path.exists(caminho_log):\n",
    "            print(\"\\nğŸ“„ ConteÃºdo do Log_Duplicatas.txt:\")\n",
    "            with open(caminho_log, \"r\", encoding=\"utf-8\") as log:\n",
    "                print(log.read())\n",
    "# Verificar estatisticas do DataFrame consolidado\n",
    "        print(\"\\nğŸ“Š EstatÃ­sticas do DataFrame consolidado:\")\n",
    "# Data minima e mÃ¡xima\n",
    "        print(\"ğŸ“… Data mÃ­nima:\", Dados_consolidado['Data'].min())\n",
    "        print(\"ğŸ“… Data mÃ¡xima:\", Dados_consolidado['Data'].max())\n",
    "# Agrupar e conta pela data\n",
    "        Total_Registros = Dados_consolidado.groupby('Data').size().reset_index(name='Quantidade')\n",
    "        print(\"\\nğŸ“… VisÃ£o por Data e Qtd:\", Total_Registros)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
